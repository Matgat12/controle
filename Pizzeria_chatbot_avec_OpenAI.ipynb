{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matgat12/controle/blob/master/Pizzeria_chatbot_avec_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7gLt1faN1VH"
      },
      "outputs": [],
      "source": [
        "# Commencez par installer les paquets nécessaires d'OpenAI\n",
        "# Pour installer des paquets dans Colab, comme si on était dans sa terminale, on utilise !\n",
        "! pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip show openai"
      ],
      "metadata": {
        "id": "LgHw5vt0-L7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importez votre clé d'API OpenAI. Pour faire cet exercise, il vous faudra créer votre propre clé.\n",
        "# Pour en savoir plus : https://platform.openai.com/docs/overview\n",
        "import openai\n",
        "openai.api_key = \"votre cle\""
      ],
      "metadata": {
        "id": "Fxs3QcSbOCNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo-1106\", temperature=0): # l'un des paramètres qu'on peut utiliser et la réponse en format Json, très pratique !\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature\n",
        "        )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "FuOpSApeoDFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_messages(_):\n",
        "    prompt = inp.value_input\n",
        "    inp.value = ''\n",
        "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
        "    response = get_completion_from_messages(context)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, styles={'background-color': '#F6F6F6'})))\n",
        "\n",
        "    return pn.Column(*panels)"
      ],
      "metadata": {
        "id": "qvBnhAnU2ON7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "\n",
        "panels = [] # collect display\n",
        "\n",
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "Tu es un chatbot, un service automatisé de collecte des commandes pour une pizzeria. \\\n",
        "Tu te présentes d'abord auprès du client, puis tu récupéres sa commande, \\\n",
        "puis tu demandes s'il s'agit d'une commande à emporter ou d'une livraison. \\\n",
        "Tu attends de récupérer la totalité de la commande, puis la valides auprès du client et tu vérifies si le client souhaite ajouter autre chose. \\\n",
        "S'il s'agit d'une livraison, tu  demandes une adresse. \\\n",
        "Enfin, tu encaisses le paiement.\\\n",
        "Assure-toi de clarifier toutes les options, extras et tailles afin de bien identifier l'élément dans le menu.\\\n",
        "Tu répondes toujours dans un style court et très convivial. \\\n",
        "Le menu comprend \\\n",
        "pizza au pepperoni 12,95, 10,00, 7,00 \\\n",
        "pizza au fromage 10,95, 9,25, 6,50 \\\n",
        "pizza aux aubergines 11,95, 9,75, 6,75 \\\n",
        "frites 4,50, 3,50\\\n",
        "salade grecque 7.25\\\n",
        "Garnitures : \\\n",
        "fromage supplémentaire 2,00, \\\n",
        "champignons 1,50 \\\n",
        "saucisse 3,00 \\\n",
        "bacon canadien 3.50\\\n",
        "Sauce IA 1,50\\\n",
        "poivrons 1,00 \\\n",
        "Boissons : \\\n",
        "coca 3,00, 2,00, 1,00 \\\n",
        "sprite 3,00, 2,00, 1,00 \\\n",
        "eau en bouteille 5,00 \\\n",
        "tous les prix sont en euros\n",
        "\"\"\"} ]  # accumulate messages\n",
        "\n",
        "\n",
        "inp = pn.widgets.TextInput(value=\"Bonjour\", placeholder='Tapez votre texte ici')\n",
        "button_conversation = pn.widgets.Button(name=\"Envoyer\")\n",
        "\n",
        "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, height=1200),\n",
        ")\n",
        "\n",
        "dashboard"
      ],
      "metadata": {
        "id": "cmvQ2QbI3jIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages =  context.copy()\n",
        "messages.append(\n",
        "{'role':'system', 'content':'crée un tableau en format json de la commande précédente et limite ta réponse à ce tableau. Ta réponse doit être en format json et ne doit pas contenir de texte avant ni après. Détaille le prix de chaque article\\\n",
        " Les champs doivent être 1) pizza 2) taille 3) liste des garnitures 4) liste des boissons, inclure la taille 5) liste des accompagnements, inclure la taille 6) prix total 7) livraison'},\n",
        ")\n",
        "\n",
        "response = get_completion_from_messages(messages, temperature=0)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "WnLXwqWSBgHb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}